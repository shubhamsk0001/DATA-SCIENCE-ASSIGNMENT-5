{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf90cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "1. What is the Naive Approach in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d730ff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "A naive classifier model is one that does not use any sophistication in order to make a prediction, typically making \n",
    "a random or constant prediction. Such models are naive because they don't use any knowledge about the domain or any \n",
    "learning in order to make a prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bd7cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "2. Explain the assumptions of feature independence in the Naive Approach."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb5dbc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "The assumption of feature independence in Naive Bayes simplifies the computation and makes the algorithm more efficient. \n",
    "By assuming independence, the joint probability of features given the class can be computed as the product of individual \n",
    "feature probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf1b5a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "3. How does the Naive Approach handle missing values in the data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1cd4c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Naïve Bayes Imputation (NBI) is used to fill in missing values by replacing the attribute information according to the \n",
    "probability estimate. The NBI process divides the whole data into two sub-sets is the complete data and data containing \n",
    "missing data. Complete data is used for the imputation process at the lost value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b36095b",
   "metadata": {},
   "outputs": [],
   "source": [
    "4. What are the advantages and disadvantages of the Naive Approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e0692c",
   "metadata": {},
   "outputs": [],
   "source": [
    "The advantage is that it is inexpensive to develop, store data, and operate. The disadvantage is that it does not consider\n",
    "any possible causal relationships that underly the forecasted variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cc91b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Can the Naive Approach be used for regression problems? If yes, how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c43b4fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Naive Bayes is a supervised classification algorithm that is used primarily for dealing with binary and multi-class \n",
    "classification problems, though with some modifications, it can also be used for solving regression problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f750f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "6. How do you handle categorical features in the Naive Approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08771d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Step 1: Drop columns with categorical data. You'll get started with the most straightforward approach. ...\n",
    "Step 2: Label encoding. Before jumping into label encoding, we'll investigate the dataset. ...\n",
    "Step 3: Investigating cardinality. ...\n",
    "Step 4: One-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36d116d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "7. What is Laplace smoothing and why is it used in the Naive Approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beed8fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Laplace smoothing is a smoothing technique that helps tackle the problem of zero probability in the Naïve Bayes machine \n",
    "learning algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33943680",
   "metadata": {},
   "outputs": [],
   "source": [
    "8. How do you choose the appropriate probability threshold in the Naive Approach?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdf9f98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "You should look for every positively classified documents in each and every class from the learning set. You have to look\n",
    "for the minimum probability required to classify particular document truly in its class. You can use this minimum \n",
    "probability as threshold for the classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff196fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "9. Give an example scenario where the Naive Approach can be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5da00297",
   "metadata": {},
   "outputs": [],
   "source": [
    "Some best examples of the Naive Bayes Algorithm are sentimental analysis, classifying new articles, and spam filtration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3238b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "10. What is the K-Nearest Neighbors (KNN) algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679725a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "The k-nearest neighbors algorithm, also known as KNN or k-NN, is a non-parametric, supervised learning classifier, which\n",
    "uses proximity to make classifications or predictions about the grouping of an individual data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1efa8f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "11. How does the KNN algorithm work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd42709c",
   "metadata": {},
   "outputs": [],
   "source": [
    "First, the distance between the new point and each training point is calculated.\n",
    "The closest k data points are selected (based on the distance). ...\n",
    "The average of these data points is the final prediction for the new point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0ce389",
   "metadata": {},
   "outputs": [],
   "source": [
    "12. How do you choose the value of K in KNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdfb808",
   "metadata": {},
   "outputs": [],
   "source": [
    "The small K value isn't suitable for classification. The optimal K value usually found is the square root of N, where N \n",
    "is the total number of samples. Use an error plot or accuracy plot to find the most favorable K value. KNN performs well \n",
    "with multi-label classes, but you must be aware of the outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899fdc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "13. What are the advantages and disadvantages of the KNN algorithm?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9a4588",
   "metadata": {},
   "outputs": [],
   "source": [
    "Advantagesof the KNN algorithm are:-\n",
    "Simple and Easy to Understand.\n",
    "Non-parametric.\n",
    "No Training Required.\n",
    "Can Handle Large Datasets.\n",
    "Disadvantagesof the KNN algorithm are:-\n",
    "Sensitive to Outliers.\n",
    "Computationally Expensive.\n",
    "Requires Good Choice of K.\n",
    "Limited to Euclidean Distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede59ea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "14. How does the choice of distance metric affect the performance of KNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05128b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "In addition, the performance of the KNN with this top performing distance degraded only ∼20% while the noise level reaches\n",
    "90%, this is true for most of the distances used as well. This means that the KNN classifier using any of the top 10 \n",
    "distances tolerates noise to a certain degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a772243",
   "metadata": {},
   "outputs": [],
   "source": [
    "15. Can KNN handle imbalanced datasets? If yes, how?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06f2afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Like many other machine learning schemes, the performance of k-NN classifiers will be significantly impacted by the \n",
    "imbalanced class distributions of data. That is, the data instances in the majority class tend to dominate the prediction\n",
    "of the test instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e344077b",
   "metadata": {},
   "outputs": [],
   "source": [
    "16. How do you handle categorical features in KNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "817ff638",
   "metadata": {},
   "outputs": [],
   "source": [
    "You have to decide how to convert categorical features to a numeric scale, and somehow assign inter-category distances in \n",
    "a way that makes sense with other features (like, age-age distances...but what is an age-category distance?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44fdbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "17. What are some techniques for improving the efficiency of KNN?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2ec484",
   "metadata": {},
   "outputs": [],
   "source": [
    "In order to improve the efficiency and speed of KNN, reducing the dimensionality of the data is necessary. The curse of \n",
    "dimensionality can make the distance between data points less distinguishable and increase complexity for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860d60f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "18. Give an example scenario where KNN can be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67eb672b",
   "metadata": {},
   "outputs": [],
   "source": [
    "With the help of KNN algorithms, we can classify a potential voter into various classes like “Will Vote”, “Will not Vote”,\n",
    "“Will Vote to Party 'Congress', “Will Vote to Party 'BJP'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03a9eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "19. What is clustering in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b54ea47",
   "metadata": {},
   "outputs": [],
   "source": [
    "Clustering is the task of dividing the population or data points into a number of groups such that data points in the \n",
    "same groups are more similar to other data points in the same group and dissimilar to the data points in other groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34357863",
   "metadata": {},
   "outputs": [],
   "source": [
    "20. Explain the difference between hierarchical clustering and k-means clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a761a3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "k-means is method of cluster analysis using a pre-specified no. of clusters. It requires advance knowledge of 'K'.\n",
    "Hierarchical clustering also known as hierarchical cluster analysis (HCA) is also a method of cluster analysis which \n",
    "seeks to build a hierarchy of clusters without having fixed number of cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ddca20",
   "metadata": {},
   "outputs": [],
   "source": [
    "21. How do you determine the optimal number of clusters in k-means clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a3984f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Compute clustering algorithm (e.g., k-means clustering) for different values of k. ...\n",
    "For each k, calculate the average silhouette of observations (avg. ...\n",
    "Plot the curve of avg. ...\n",
    "The location of the maximum is considered as the appropriate number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c4e2a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "22. What are some common distance metrics used in clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c75cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Distance metrics are used in supervised and unsupervised learning to calculate similarity in data points. They improve \n",
    "the performance, whether that's for classification tasks or clustering. The four types of distance metrics are \n",
    "Euclidean Distance, Manhattan Distance, Minkowski Distance, and Hamming Distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c2cd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "23. How do you handle categorical features in clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b627ed88",
   "metadata": {},
   "outputs": [],
   "source": [
    "One way to handle categorical variables is to use one-hot encoding. One-hot encoding transforms categorical variables into\n",
    "a set of binary features, where each feature represents a distinct category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62ffa6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "24. What are the advantages and disadvantages of hierarchical clustering?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b374ee4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "Advantages of Hierarchical clustering\n",
    "It is simple to implement and gives the best output in some cases. It is easy and results in a hierarchy, a structure that\n",
    "contains more information. It does not need us to pre-specify the number of clusters.\n",
    "Disadvantages of hierarchical clustering\n",
    "It breaks the large clusters. It is Difficult to handle different sized clusters and convex shapes. It is sensitive to \n",
    "noise and outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d81781",
   "metadata": {},
   "outputs": [],
   "source": [
    "25. Explain the concept of silhouette score and its interpretation in clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debd3565",
   "metadata": {},
   "outputs": [],
   "source": [
    "The silhouette value is a measure of how similar an object is to its own cluster (cohesion) compared to other clusters\n",
    "(separation). The silhouette ranges from −1 to +1, where a high value indicates that the object is well matched to its own\n",
    "cluster and poorly matched to neighboring clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69e4a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "26. Give an example scenario where clustering can be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f2db829",
   "metadata": {},
   "outputs": [],
   "source": [
    "Here are 7 examples of clustering algorithms in action.\n",
    "Identifying Fake News. Fake news is not a new phenomenon, but it is one that is becoming prolific. ...\n",
    "Spam filter. ...\n",
    "Marketing and Sales. ...\n",
    "Classifying network traffic. ...\n",
    "Identifying fraudulent or criminal activity. ...\n",
    "Document analysis. ...\n",
    "Fantasy Football and Sports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2f0a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "27. What is anomaly detection in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750a871f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Anomaly detection (aka outlier analysis) is a step in data mining that identifies data points, events, and/or observations \n",
    "that deviate from a dataset's normal behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c439a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "28. Explain the difference between supervised and unsupervised anomaly detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d059afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "The main difference between supervised and unsupervised anomaly detection is the approach involved, where supervised \n",
    "approach makes use of predefined algorithms and AI training, while unsupervised approach uses a general outlier-detection\n",
    "mechanism based on pattern matching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37394aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "29. What are some common techniques used for anomaly detection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5ebdf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "Some of the popular techniques are:\n",
    "1.Statistical (Z-score, Tukey's range test and Grubbs's test)\n",
    "2.Density-based techniques (k-nearest neighbor, local outlier factor, isolation forests, and many more variations of this \n",
    "concept)\n",
    "3.Subspace-, correlation-based and tensor-based outlier detection for high-dimensional data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5df8294",
   "metadata": {},
   "outputs": [],
   "source": [
    "30. How does the One-Class SVM algorithm work for anomaly detection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9867acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "One-class SVM, or unsupervised SVM, is an algorithm used for anomaly detection. The algorithm tries to separate data from\n",
    "the origin in the transformed high-dimensional predictor space. ocsvm finds the decision boundary based on the primal form\n",
    "of SVM with the Gaussian kernel approximation method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49aa03e",
   "metadata": {},
   "outputs": [],
   "source": [
    "31. How do you choose the appropriate threshold for anomaly detection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c13a5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "For Anomaly detection threshold, choose the number to use for the anomaly detection threshold. A higher number creates a\n",
    "thicker band of \"normal\" values that is more tolerant of metric changes. A lower number creates a thinner band that will \n",
    "go to ALARM state with smaller metric deviations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e2283f",
   "metadata": {},
   "outputs": [],
   "source": [
    "32. How do you handle imbalanced datasets in anomaly detection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5562f43",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.Choose Proper Evaluation Metric. The accuracy of a classifier is the total number of correct predictions by the \n",
    "classifier divided by the total number of predictions. ...\n",
    "2.Resampling (Oversampling and Undersampling) ...\n",
    "3.SMOTE. ...\n",
    "4.BalancedBaggingClassifier. ...\n",
    "5.Threshold moving."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da2f279",
   "metadata": {},
   "outputs": [],
   "source": [
    "33. Give an example scenario where anomaly detection can be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d759093",
   "metadata": {},
   "outputs": [],
   "source": [
    "For example, a credit card company will use anomaly detection to track how customers typically use their credit cards. \n",
    "If a customer makes an abnormally large purchase or a purchase in a new location, the algorithm recognizes the anomaly \n",
    "and alerts a team member to contact the customer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e791f2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "34. What is dimension reduction in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889469e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "Dimensionality reduction is the process of reducing the number of features in a dataset while retaining as much \n",
    "information as possible. This can be done to reduce the complexity of a model, improve the performance of a learning \n",
    "algorithm, or make it easier to visualize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a331b173",
   "metadata": {},
   "outputs": [],
   "source": [
    "35. Explain the difference between feature selection and feature extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bce33be",
   "metadata": {},
   "outputs": [],
   "source": [
    "The key difference between feature selection and feature extraction techniques used for dimensionality reduction is that\n",
    "while the original features are maintained in the case of feature selection algorithms, the feature extraction algorithms \n",
    "transform the data onto a new feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d33ea7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "36. How does Principal Component Analysis (PCA) work for dimension reduction?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8f933f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PCA helps us to identify patterns in data based on the correlation between features. In a nutshell, PCA aims to find the\n",
    "directions of maximum variance in high-dimensional data and projects it onto a new subspace with equal or fewer dimensions\n",
    "than the original one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f26ead7",
   "metadata": {},
   "outputs": [],
   "source": [
    "37. How do you choose the number of components in PCA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8f9769",
   "metadata": {},
   "outputs": [],
   "source": [
    "If our sole intention of doing PCA is for data visualization, the best number of components is 2 or 3. If we really want\n",
    "to reduce the size of the dataset, the best number of principal components is much less than the number of variables in\n",
    "the original dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9682cbe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "38. What are some other dimension reduction techniques besides PCA?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213ea93b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Some other dimension reduction techniques beside PCA are:-\n",
    "singular value decomposition (SVD), and linear discriminant analysis (LDA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1979c303",
   "metadata": {},
   "outputs": [],
   "source": [
    "39. Give an example scenario where dimension reduction can be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "520e52bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Prior Variable Analysis and Principal Component Analysis are both examples of a data reduction algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cba58b",
   "metadata": {},
   "outputs": [],
   "source": [
    "40. What is feature selection in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea03c197",
   "metadata": {},
   "outputs": [],
   "source": [
    "Feature Selection is the method of reducing the input variable to your model by using only relevant data and getting rid \n",
    "of noise in data. It is the process of automatically choosing relevant features for your machine learning model based on\n",
    "the type of problem you are trying to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca66968",
   "metadata": {},
   "outputs": [],
   "source": [
    "41. Explain the difference between filter, wrapper, and embedded methods of feature selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "848922e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "Filter method is faster and useful when there are more number of features. Wrapper method gives better performance \n",
    "while the embedded method lies in between the other two methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d952ef16",
   "metadata": {},
   "outputs": [],
   "source": [
    "42. How does correlation-based feature selection work?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f334d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "A feature evaluation formula, based on ideas from test theory, provides an operational definition of this hypothesis. \n",
    "CFS (Correlation based Feature Selection) is an algorithm that couples this evaluation formula with an appropriate \n",
    "correlation measure and a heuristic search strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf563a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "43. How do you handle multicollinearity in feature selection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "446fa49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.Removing variables. A straightforward method of correcting multicollinearity is removing one or more variables showing a \n",
    "high correlation. ...\n",
    "2.More data. ...\n",
    "3.Using techniques such as partial least squares regression (PLS) and principal component analysis (PCA). ...\n",
    "4.Centering the variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13524448",
   "metadata": {},
   "outputs": [],
   "source": [
    "44. What are some common feature selection metrics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc20cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "Some examples of embedded methods include decision tree-based algorithms (e.g., decision tree, random forest, \n",
    "gradient boosting), and feature selection using regularization models (e.g., LASSO or elastic net)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ac6c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "45. Give an example scenario where feature selection can be applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d453a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Below are some real-life examples of feature selection: Mammographic image analysis. Criminal behavior modeling. \n",
    "Genomic data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbd4e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "46. What is data drift in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5d68849",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data drift is unexpected and undocumented changes to data structure, semantics, and infrastructure that is a result of \n",
    "modern data architectures. Data drift breaks processes and corrupts data, but can also reveal new opportunities for\n",
    "data use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed91acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "47. Why is data drift detection important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858c28c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "User behavior itself might have changed compared to the baseline data the model was trained on, or there might be \n",
    "additional factors in real-world interactions which would have impacted the predictions. Data drift is a major reason \n",
    "model accuracy decreases over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9578a01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "48. Explain the difference between concept drift and feature drift."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b21333",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data drift refers to the changing distribution of the data to which the model is applied. Concept drift refers to a \n",
    "changing underlying goal or objective for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b7be4af",
   "metadata": {},
   "outputs": [],
   "source": [
    "49. What are some techniques used for detecting data drift?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567ae60b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Time distribution-based methods use statistical methods to calculate the difference between two probability distributions \n",
    "to detect drift. These methods include the Population Stability Index, KL Divergence, JS Divergence, KS Test, and the \n",
    "Wasserstein Metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cba95a",
   "metadata": {},
   "outputs": [],
   "source": [
    "50. How can you handle data drift in a machine learning model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e932b66",
   "metadata": {},
   "outputs": [],
   "source": [
    "In light of data or concept drift, you might apply a new correction on top of the model output. For example, you can \n",
    "change the model output by X% for a given category or set minimum or maximum values to ensure the business process does\n",
    "not suffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eef1f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "51. What is data leakage in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "510907bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "In simple words, data leakage can be defined as: \"A scenario when ML model already has information of test data in\n",
    "training data, but this information would not be available at the time of prediction, called data leakage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9764f358",
   "metadata": {},
   "outputs": [],
   "source": [
    "52. Why is data leakage a concern?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fde75ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data leaks can have serious consequences for both individuals and businesses. For individuals, data leaks can lead to \n",
    "identity theft, fraud, and financial loss. For businesses, data leaks can damage the company's reputation or give \n",
    "competitors an advantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a609ee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "53. Explain the difference between target leakage and train-test contamination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d62f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Target leakage occurs when a variable that is not a feature is used to predict the target. This occurs when the model is \n",
    "built, or trained, with information (known as the training dataset) that will not be available in unseen data.\n",
    "WHEAREAS\n",
    "This happens when we unknowingly or subtly pass information from our train dataset to our validation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f960a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "54. How can you identify and prevent data leakage in a machine learning pipeline?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a80e9fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "To prevent such leakage, the dataset should be separated into training and testing sets before performing any \n",
    "preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b39e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "55. What are some common sources of data leakage?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f8d681",
   "metadata": {},
   "outputs": [],
   "source": [
    "There are three major types of data leakage. These are – data breach by accident, data leak done by ill-intentioned \n",
    "employees and electronic communication with malicious intent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3bfb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "56. Give an example scenario where data leakage can occur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a60a28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data leakage occurs when sensitive data gets unintentionally exposed to the public in transit, at rest, or in use. Here\n",
    "are common examples: Data exposed in transit — Data transmitted via emails, API calls, chat rooms, and other \n",
    "communications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddba9cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "57. What is cross-validation in machine learning?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a53d093",
   "metadata": {},
   "outputs": [],
   "source": [
    "Cross validation is a technique used in machine learning to evaluate the performance of a model on unseen data. It \n",
    "involves dividing the available data into multiple folds or subsets, using one of these folds as a validation set, \n",
    "and training the model on the remaining folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66277831",
   "metadata": {},
   "outputs": [],
   "source": [
    "58. Why is cross-validation important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d68393",
   "metadata": {},
   "outputs": [],
   "source": [
    "The main advantage of cross-validation is that it provides an estimate of the performance of the model on new data, which \n",
    "is important for assessing the model's generalizability. It also helps to avoid overfitting, which is a common problem in \n",
    "machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47544be",
   "metadata": {},
   "outputs": [],
   "source": [
    "59. Explain the difference between k-fold cross-validation and stratified k-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3018f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stratified k-fold cross-validation is the same as just k-fold cross-validation, But Stratified k-fold cross-validation, \n",
    "it does stratified sampling instead of random sampling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d7e450c",
   "metadata": {},
   "outputs": [],
   "source": [
    "60. How do you interpret the cross-validation results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e950975",
   "metadata": {},
   "outputs": [],
   "source": [
    "K-fold cross-validation is a technique for evaluating predictive models. The dataset is divided into k subsets or folds.\n",
    "The model is trained and evaluated k times, using a different fold as the validation set each time. Performance metrics \n",
    "from each fold are averaged to estimate the model's generalization performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
